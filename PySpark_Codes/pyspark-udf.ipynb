{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"\n", "author SparkByExamples.com\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pyspark\n", "from pyspark.sql import SparkSession\n", "from pyspark.sql.functions import col, udf\n", "from pyspark.sql.types import StringType"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["columns = [\"Seqno\",\"Name\"]\n", "data = [(\"1\", \"john jones\"),\n", "    (\"2\", \"tracey smith\"),\n", "    (\"3\", \"amy sanders\")]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = spark.createDataFrame(data=data,schema=columns)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.show(truncate=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convertCase(str):\n", "    resStr=\"\"\n", "    arr = str.split(\" \")\n", "    for x in arr:\n", "       resStr= resStr + x[0:1].upper() + x[1:len(x)] + \" \"\n", "    return resStr "]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n Converting function to UDF \n<br>\n", "convertUDF = udf(lambda z: convertCase(z))<br>\n", "df.select(col(\"Seqno\"), \\<br>\n", "    convertUDF(col(\"Name\")).alias(\"Name\") ) \\<br>\n", ".show(truncate=False)<br>\n", "@udf(returnType=StringType()) <br>\n", "def upperCase(str):<br>\n", "    return str.upper()<br>\n", "upperCaseUDF = udf(lambda z:upperCase(z),StringType())    <br>\n", "df.withColumn(\"Cureated Name\", upperCase(col(\"Name\"))) \\<br>\n", ".show(truncate=False)<br>\n", "Using UDF on SQL \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark.udf.register(\"convertUDF\", convertCase,StringType())\n", "df.createOrReplaceTempView(\"NAME_TABLE\")\n", "spark.sql(\"select Seqno, convertUDF(Name) as Name from NAME_TABLE\") \\\n", "     .show(truncate=False)\n", "     \n", "spark.sql(\"select Seqno, convertUDF(Name) as Name from NAME_TABLE \" + \\\n", "          \"where Name is not null and convertUDF(Name) like '%John%'\") \\\n", "     .show(truncate=False)  \n", "     \n", "\"\"\" null check \"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["columns = [\"Seqno\",\"Name\"]\n", "data = [(\"1\", \"john jones\"),\n", "    (\"2\", \"tracey smith\"),\n", "    (\"3\", \"amy sanders\"),\n", "    ('4',None)]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df2 = spark.createDataFrame(data=data,schema=columns)\n", "df2.show(truncate=False)\n", "df2.createOrReplaceTempView(\"NAME_TABLE2\")\n", "    \n", "spark.udf.register(\"_nullsafeUDF\", lambda str: convertCase(str) if not str is None else \"\" , StringType())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark.sql(\"select _nullsafeUDF(Name) from NAME_TABLE2\") \\\n", "     .show(truncate=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark.sql(\"select Seqno, _nullsafeUDF(Name) as Name from NAME_TABLE2 \" + \\\n", "          \" where Name is not null and _nullsafeUDF(Name) like '%John%'\") \\\n", "     .show(truncate=False)  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}