{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"\n", "author SparkByExamples.com\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql import SparkSession\n", "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql.functions import expr\n", "#Concatenate columns\n", "data=[(\"James\",\"Bond\"),(\"Scott\",\"Varsa\")] \n", "df=spark.createDataFrame(data).toDF(\"col1\",\"col2\") \n", "df.withColumn(\"Name\",expr(\" col1 ||','|| col2\")).show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["sing CASE WHEN sql expression"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = [(\"James\",\"M\"),(\"Michael\",\"F\"),(\"Jen\",\"\")]\n", "columns = [\"name\",\"gender\"]\n", "df = spark.createDataFrame(data = data, schema = columns)\n", "df2 = df.withColumn(\"gender\", expr(\"CASE WHEN gender = 'M' THEN 'Male' \" +\n", "           \"WHEN gender = 'F' THEN 'Female' ELSE 'unknown' END\"))\n", "df2.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["dd months from a value of another column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data=[(\"2019-01-23\",1),(\"2019-06-24\",2),(\"2019-09-20\",3)] \n", "df=spark.createDataFrame(data).toDF(\"date\",\"increment\") \n", "df.select(df.date,df.increment,\n", "     expr(\"add_months(date,increment)\")\n", "  .alias(\"inc_date\")).show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Providing alias using 'as'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.select(df.date,df.increment,\n", "     expr(\"\"\"add_months(date,increment) as inc_date\"\"\")\n", "  ).show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.select(df.date,df.increment,\n", "     expr(\"increment + 5 as new_increment\")\n", "  ).show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.select(\"increment\",expr(\"cast(increment as string) as str_increment\")) \\\n", "  .printSchema()\n", "#Use expr()  to filter the rows\n", "data=[(100,2),(200,3000),(500,500)] \n", "df=spark.createDataFrame(data).toDF(\"col1\",\"col2\") \n", "df.filter(expr(\"col1 == col2\")).show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}