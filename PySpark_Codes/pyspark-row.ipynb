{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"\n", "author SparkByExamples.com\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql import SparkSession, Row"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["row=Row(\"James\",40)\n", "print(row[0] +\",\"+str(row[1]))\n", "row2=Row(name=\"Alice\", age=11)\n", "print(row2.name)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Person = Row(\"name\", \"age\")\n", "p1=Person(\"James\", 40)\n", "p2=Person(\"Alice\", 35)\n", "print(p1.name +\",\"+p2.name)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ySpark Example"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rdd2 = spark.sparkContext.parallelize([],10)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = [Row(name=\"James,,Smith\",lang=[\"Java\",\"Scala\",\"C++\"],state=\"CA\"), \n", "    Row(name=\"Michael,Rose,\",lang=[\"Spark\",\"Java\",\"C++\"],state=\"NJ\"),\n", "    Row(name=\"Robert,,Williams\",lang=[\"CSharp\",\"VB\"],state=\"NV\")]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["DD Example 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rdd=spark.sparkContext.parallelize(data)\n", "collData=rdd.collect()\n", "print(collData)\n", "for row in collData:\n", "    print(row.name + \",\" +str(row.lang))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["RDD Example 2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Person=Row(\"name\",\"lang\",\"state\")\n", "data = [Person(\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],\"CA\"), \n", "    Person(\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],\"NJ\"),\n", "    Person(\"Robert,,Williams\",[\"CSharp\",\"VB\"],\"NV\")]\n", "rdd=spark.sparkContext.parallelize(data)\n", "collData=rdd.collect()\n", "print(collData)\n", "for person in collData:\n", "    print(person.name + \",\" +str(person.lang))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ataFrame Example 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["columns = [\"name\",\"languagesAtSchool\",\"currentState\"]\n", "df=spark.createDataFrame(data)\n", "df.printSchema()\n", "df.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["collData=df.collect()\n", "print(collData)\n", "for row in collData:\n", "    print(row.name + \",\" +str(row.lang))\n", "    \n", "#DataFrame Example 2\n", "data = [(\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],\"CA\"), \n", "(\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],\"NJ\"),\n", "(\"Robert,,Williams\",[\"CSharp\",\"VB\"],\"NV\")]\n", "columns = [\"name\",\"languagesAtSchool\",\"currentState\"]\n", "df=spark.createDataFrame(data).toDF(*columns)\n", "df.printSchema()\n", "for row in df.collect():\n", "    print(row.name)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}